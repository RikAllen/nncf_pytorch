From b0ebeee00abf486f9a3ed84f50def781538a4cdc Mon Sep 17 00:00:00 2001
From: cuderona <git@abrainsight.com>
Date: Thu, 5 Nov 2020 20:39:13 +0000
Subject: [PATCH] Squashed commits x4

---
 data/coco2017.data |  4 ++--
 models.py          |  4 ++--
 test.py            | 59 +++++++++++++++++++++++++++++++++++++++-------
 train.py           | 58 ++++++++++++++++++++++++++++++++++++++-------
 utils/datasets.py  |  7 ++++--
 5 files changed, 109 insertions(+), 23 deletions(-)

diff --git a/data/coco2017.data b/data/coco2017.data
index c946005..40a9c0d 100644
--- a/data/coco2017.data
+++ b/data/coco2017.data
@@ -1,4 +1,4 @@
 classes=80
-train=../coco/train2017.txt
-valid=../coco/val2017.txt
+train=pathto/coco/train2017.txt
+valid=pathto/coco/val2017.txt
 names=data/coco.names
diff --git a/models.py b/models.py
index 54742b8..024cdab 100755
--- a/models.py
+++ b/models.py
@@ -190,8 +190,8 @@ class YOLOLayer(nn.Module):
             bs = 1  # batch size
         else:
             bs, _, ny, nx = p.shape  # bs, 255, 13, 13
-            if (self.nx, self.ny) != (nx, ny):
-                self.create_grids((nx, ny), p.device)
+            # if (self.nx, self.ny) != (nx, ny):
+            self.create_grids((nx, ny), p.device)
 
         # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)
         p = p.view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction
diff --git a/test.py b/test.py
index 4d68438..6ecf9b0 100644
--- a/test.py
+++ b/test.py
@@ -2,11 +2,21 @@ import argparse
 import json
 
 from torch.utils.data import DataLoader
+from nncf import NNCFConfig as Config, create_compressed_model, load_state
 
 from models import *
 from utils.datasets import *
 from utils.utils import *
+from torch import onnx
+import os.path as osp
 
+retrained = True
+ONNX_EXPORT = False
+
+def dummy_forward(model):
+    device = next(model.parameters()).device
+    input_args = [torch.randn(1, 3, 416, 416).to(device),]
+    model(*input_args)
 
 def test(cfg,
          data,
@@ -34,24 +44,57 @@ def test(cfg,
         # Initialize model
         model = Darknet(cfg, imgsz)
 
+        ### To test low precision on original Darknet weights - set --weights path in command line to yolov3-tiny.pt
+        if not retrained:
+            model.load_state_dict(torch.load(weights, map_location="cuda:0")['model'])                
+        
+        config_path = "../tinyyolov3_Ultralytics.json"
+        nncf_config = Config.from_json(config_path)
+        compression_ctrl, model = create_compressed_model(model, nncf_config, dummy_forward_fn=dummy_forward)
+
+        ### To load weights trained on compressed network - set --weights path in command line
+        if retrained:
+            if ONNX_EXPORT:
+                map_location = "cpu"
+            else:
+                map_location = device
+            model.load_state_dict(torch.load(weights, map_location=map_location)['model'])
+        
         # Load weights
-        attempt_download(weights)
-        if weights.endswith('.pt'):  # pytorch format
-            model.load_state_dict(torch.load(weights, map_location=device)['model'])
-        else:  # darknet format
-            load_darknet_weights(model, weights)
+        # attempt_download(weights)
+        # if weights.endswith('.pt'):  # pytorch format
+        #     model.load_state_dict(torch.load(weights, map_location=device)['model'])
+        # else:  # darknet format
+        #     load_darknet_weights(model, weights)
 
         # Fuse
-        model.fuse()
+        # model.fuse()
+        # print(model)
+
+        ### To export a compressed model to ONNX. Set opset_version in compression_method_api.py of NNCF: 
+        ###   10 if < OpenVINO 2021.1, 11 otherwise
+        if retrained and ONNX_EXPORT:
+            model_name = "test" #TinyYOLOv3_unretrained_unfused_int54bfpconfig_opset11
+            compression_ctrl.export_model("onnxFiles/" + model_name + ".onnx")
+            exit()
+
+
+        if not retrained and ONNX_EXPORT:
+            # To export the original model to ONNX. Opset 11 is compatible with OpenVINO version 2021.1 and above
+            torch.onnx.export(model, torch.randn(1, 3, 416, 416), "onnxFiles/TinyYOLOv3_Darknet_opset11_fused.onnx", verbose=True, opset_version=11,
+                                input_names=['images'], output_names=['classes', 'boxes'])
+            exit()
+
         model.to(device)
 
         if device.type != 'cpu' and torch.cuda.device_count() > 1:
-            model = nn.DataParallel(model)
+            model = nn.DataParallel(model) 
+
     else:  # called by train.py
         is_training = True
         device = next(model.parameters()).device  # get model device
         verbose = False
-
+    
     # Configure run
     data = parse_data_cfg(data)
     nc = 1 if single_cls else int(data['classes'])  # number of classes
diff --git a/train.py b/train.py
index 1aba8d2..a7f4a4a 100644
--- a/train.py
+++ b/train.py
@@ -1,3 +1,5 @@
+# To run: python3 train.py --cfg cfg/yolov3-tiny.cfg --weights weights/yolov3-tiny.pt
+
 import argparse
 
 import torch.distributed as dist
@@ -10,6 +12,11 @@ from models import *
 from utils.datasets import *
 from utils.utils import *
 
+import nncf
+from nncf import NNCFConfig as Config, create_compressed_model, load_state
+from nncf import register_default_init_args
+from examples.object_detection.layers.modules import MultiBoxLoss
+
 mixed_precision = True
 try:  # Mixed precision training https://github.com/NVIDIA/apex
     from apex import amp
@@ -18,8 +25,8 @@ except:
     mixed_precision = False  # not installed
 
 wdir = 'weights' + os.sep  # weights dir
-last = wdir + 'last.pt'
-best = wdir + 'best.pt'
+last = wdir + 'NNCF_last.pt'
+best = wdir + 'NNCF_best.pt'
 results_file = 'results.txt'
 
 # Hyperparameters
@@ -29,7 +36,7 @@ hyp = {'giou': 3.54,  # giou loss gain
        'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)
        'obj_pw': 1.0,  # obj BCELoss positive_weight
        'iou_t': 0.20,  # iou training threshold
-       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)
+       'lr0': 0.001,  # initial learning rate (SGD=5E-3, Adam=5E-4)
        'lrf': 0.0005,  # final learning rate (with cos scheduler)
        'momentum': 0.937,  # SGD momentum
        'weight_decay': 0.0005,  # optimizer weight decay
@@ -53,6 +60,10 @@ if f:
 if hyp['fl_gamma']:
     print('Using FocalLoss(gamma=%g)' % hyp['fl_gamma'])
 
+def dummy_forward(model):
+    device = next(model.parameters()).device
+    input_args = [torch.randn(1, 3, 416, 416).to(device),]
+    model(*input_args)
 
 def train(hyp):
     cfg = opt.cfg
@@ -206,6 +217,14 @@ def train(hyp):
                                              shuffle=not opt.rect,  # Shuffle=True unless rectangular training is used
                                              pin_memory=True,
                                              collate_fn=dataset.collate_fn)
+    #### NNCF ####
+    config_path = "../tinyyolov3_Ultralytics.json"
+    nncf_config = Config.from_json(config_path)
+       
+    criterion = nn.CrossEntropyLoss()
+    criterion = criterion.to(device)
+    nncf_config = register_default_init_args(nncf_config, criterion, dataloader)
+    #### NNCF ####
 
     # Testloader
     testloader = torch.utils.data.DataLoader(LoadImagesAndLabels(test_path, imgsz_test, batch_size,
@@ -237,6 +256,14 @@ def train(hyp):
     print('Image sizes %g - %g train, %g test' % (imgsz_min, imgsz_max, imgsz_test))
     print('Using %g dataloader workers' % nw)
     print('Starting training for %g epochs...' % epochs)
+    
+    # print(model)
+    
+    #### NNCF ####
+    compression_ctrl, compressed_model = create_compressed_model(model, nncf_config, dummy_forward_fn=dummy_forward)
+    # print(compressed_model)
+    #### NNCF ####
+    
     for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------
         model.train()
 
@@ -247,6 +274,8 @@ def train(hyp):
             dataset.indices = random.choices(range(dataset.n), weights=image_weights, k=dataset.n)  # rand weighted idx
 
         mloss = torch.zeros(4).to(device)  # mean losses
+        print(optimizer.param_groups[0]['lr'])
         print(('\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))
         pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar
         for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------
@@ -280,6 +309,13 @@ def train(hyp):
 
             # Loss
             loss, loss_items = compute_loss(pred, targets, model)
+
+            #### NNCF ####
+            compression_loss = compression_ctrl.loss()
+            loss = loss + compression_loss
+            loss_items[3] = loss_items[3] + compression_loss
+            #### NNCF ####
+
             if not torch.isfinite(loss):
                 print('WARNING: non-finite loss, ending training ', loss_items)
                 return results
@@ -317,6 +353,10 @@ def train(hyp):
         # Update scheduler
         scheduler.step()
 
+        #### NNCF ####
+        compression_ctrl.scheduler.step()
+        #### NNCF ####
+
         # Process epoch results
         ema.update_attr(model)
         final_epoch = epoch + 1 == epochs
@@ -326,7 +366,7 @@ def train(hyp):
                                       data,
                                       batch_size=batch_size,
                                       imgsz=imgsz_test,
-                                      model=ema.ema,
+                                      model=compressed_model, #ema.ema,
                                       save_json=final_epoch and is_coco,
                                       single_cls=opt.single_cls,
                                       dataloader=testloader,
@@ -356,17 +396,17 @@ def train(hyp):
         if save:
             with open(results_file, 'r') as f:  # create checkpoint
                 ckpt = {'epoch': epoch,
-                        'best_fitness': best_fitness,
-                        'training_results': f.read(),
-                        'model': ema.ema.module.state_dict() if hasattr(model, 'module') else ema.ema.state_dict(),
-                        'optimizer': None if final_epoch else optimizer.state_dict()}
+                         'best_fitness': best_fitness,
+                         'training_results': f.read(),
+                         'model': compressed_model.state_dict(), #ema.ema.module.state_dict() if hasattr(model, 'module') else ema.ema.state_dict(),
+                         'optimizer': None if final_epoch else optimizer.state_dict()}
 
             # Save last, best and delete
             torch.save(ckpt, last)
             if (best_fitness == fi) and not final_epoch:
                 torch.save(ckpt, best)
             del ckpt
-
+        compression_ctrl.scheduler.epoch_step()
         # end epoch ----------------------------------------------------------------------------------------------------
     # end training
 
diff --git a/utils/datasets.py b/utils/datasets.py
index 6bb8180..a507f14 100755
--- a/utils/datasets.py
+++ b/utils/datasets.py
@@ -349,7 +349,9 @@ class LoadImagesAndLabels(Dataset):  # for training/testing
                 # np.savetxt(file, l, '%g')  # save *.txt from *.npy file
             else:
                 try:
-                    with open(file, 'r') as f:
+                    # with open(file, 'r') as f:
+                    # for i, file in enumerate(pbar):
+                    with open(os.path.join('/media/cuderona/e45a3166-8222-4a6f-87ac-2cc3dd80c22e/COCO/dev/ultralytics_yolov3/coco/',file), 'r') as f:
                         l = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32)
                 except:
                     nm += 1  # print('missing labels for image %s' % self.img_files[i])  # file missing
@@ -529,7 +531,8 @@ def load_image(self, index):
     img = self.imgs[index]
     if img is None:  # not cached
         path = self.img_files[index]
-        img = cv2.imread(path)  # BGR
+        # img = cv2.imread(path)  # BGR
+        img = cv2.imread(os.path.join('pathto/COCO/dev/ultralytics_yolov3/coco/',path))  # BGR
         assert img is not None, 'Image Not Found ' + path
         h0, w0 = img.shape[:2]  # orig hw
         r = self.img_size / max(h0, w0)  # resize image to img_size
-- 
2.28.0

